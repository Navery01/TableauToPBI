"""
Tableau to Power BI Converter Module

This module provides functionality to convert Tableau workbooks (.twbx) to Power BI templates (.pbit).
It extracts data sources, worksheets, and calculated fields from Tableau and converts them to 
compatible Power BI structures.

Author: Your Name
Version: 1.0.0
"""

import zipfile
import os
import xml.etree.ElementTree as ET
import json
import subprocess
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Union
import logging
import requests
import platform
import sys

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TableauToPowerBIError(Exception):
    """Custom exception for Tableau to Power BI conversion errors."""
    pass


class TableauExtractor:
    """Handles extraction and parsing of Tableau workbook files."""
    
    @staticmethod
    def extract_twbx(twbx_path: str, output_dir: Optional[str] = None) -> str:
        """
        Extract a .twbx file to a directory.
        
        Args:
            twbx_path: Path to the .twbx file
            output_dir: Output directory (creates temp dir if None)
            
        Returns:
            Path to the extracted directory
        """
        if output_dir is None:
            output_dir = tempfile.mkdtemp(prefix="twbx_extract_")
        
        try:
            os.makedirs(output_dir, exist_ok=True)
            with zipfile.ZipFile(twbx_path, 'r') as zip_ref:
                zip_ref.extractall(output_dir)
            logger.info(f"âœ… Extracted {twbx_path} to {output_dir}")
            return output_dir
        except Exception as e:
            raise TableauToPowerBIError(f"Failed to extract {twbx_path}: {e}")
    
    @staticmethod
    def find_twb_file(folder: str) -> str:
        """
        Find the .twb file in an extracted .twbx directory.
        
        Args:
            folder: Directory to search
            
        Returns:
            Path to the .twb file
        """
        for root, _, files in os.walk(folder):
            for file in files:
                if file.endswith(".twb"):
                    return os.path.join(root, file)
        raise TableauToPowerBIError("No .twb file found in extracted .twbx.")
    
    @staticmethod
    def parse_twb(twb_path: str) -> Dict:
        """
        Parse a Tableau workbook (.twb) XML file.
        
        Args:
            twb_path: Path to the .twb file
            
        Returns:
            Dictionary containing parsed workbook information
        """
        try:
            tree = ET.parse(twb_path)
            root = tree.getroot()
        except Exception as e:
            raise TableauToPowerBIError(f"Failed to parse {twb_path}: {e}")

        workbook_info = {
            "datasources": [],
            "worksheets": [],
            "calculated_fields": [],
            "joins": [],
            "parameters": [],
            "dashboards": []
        }

        # Parse data sources
        for ds in root.findall('.//datasource'):
            datasource = {
                "name": ds.get('name', 'UnnamedDataSource'),
                "fields": [],
                "connections": []
            }
            
            # Parse columns/fields
            for column in ds.findall('.//column'):
                field_info = {
                    "name": column.get('name', ''),
                    "datatype": column.get('datatype', 'string'),
                    "role": column.get('role', ''),
                    "type": column.get('type', ''),
                    "caption": column.get('caption', '')
                }
                datasource["fields"].append(field_info)
            
            # Parse connections
            for conn in ds.findall('.//connection'):
                conn_info = {
                    "class": conn.get('class', ''),
                    "dbname": conn.get('dbname', ''),
                    "server": conn.get('server', ''),
                    "authentication": conn.get('authentication', ''),
                    "port": conn.get('port', ''),
                    "username": conn.get('username', '')
                }
                datasource["connections"].append(conn_info)
            
            workbook_info["datasources"].append(datasource)

        # Parse calculated fields
        for calc in root.findall('.//calculation'):
            calc_info = {
                "name": calc.get('name', ''),
                "formula": calc.get('formula', ''),
                "class": calc.get('class', '')
            }
            workbook_info["calculated_fields"].append(calc_info)

        # Parse joins
        for relation in root.findall('.//relation'):
            if relation.get('type') == 'join':
                join_info = {
                    "left": relation.get('left', ''),
                    "right": relation.get('right', ''),
                    "operator": relation.get('operator', ''),
                    "type": relation.get('join', 'inner')
                }
                workbook_info["joins"].append(join_info)

        # Parse worksheets
        for ws in root.findall('.//worksheet'):
            worksheet_info = {
                "name": ws.get('name', ''),
                "filters": [],
                "measures": [],
                "dimensions": []
            }
            workbook_info["worksheets"].append(worksheet_info)

        # Parse parameters
        for param in root.findall('.//column[@param-domain-type]'):
            param_info = {
                "name": param.get('name', ''),
                "datatype": param.get('datatype', ''),
                "param_domain_type": param.get('param-domain-type', ''),
                "default_value": param.get('value', '')
            }
            workbook_info["parameters"].append(param_info)

        # Parse dashboards
        for dashboard in root.findall('.//dashboard'):
            dashboard_info = {
                "name": dashboard.get('name', ''),
                "worksheets": []
            }
            workbook_info["dashboards"].append(dashboard_info)

        logger.info(f"âœ… Parsed TWB file: {len(workbook_info['datasources'])} data sources, "
                   f"{len(workbook_info['worksheets'])} worksheets")
        
        return workbook_info


class PowerBIConverter:
    """Handles conversion from Tableau structures to Power BI formats."""
    
    DATATYPE_MAPPING = {
        "string": "string",
        "real": "double", 
        "integer": "int64",
        "boolean": "boolean",
        "date": "dateTime",
        "datetime": "dateTime",
        "number": "double"
    }
    
    @classmethod
    def map_datatype(cls, tableau_type: str) -> str:
        """Map Tableau data type to Power BI data type."""
        return cls.DATATYPE_MAPPING.get(tableau_type.lower(), "string")
    
    @staticmethod
    def convert_formula_to_dax(formula: str) -> str:
        """
        Convert Tableau formula to DAX (basic conversion).
        
        Args:
            formula: Tableau formula string
            
        Returns:
            DAX formula string
        """
        if not formula:
            return "BLANK()"
        
        # Basic formula conversions
        dax_formula = formula
        
        # Replace common Tableau functions with DAX equivalents
        replacements = {
            "IF ": "IF(",
            "SUM(": "SUM(",
            "COUNT(": "COUNT(",
            "AVG(": "AVERAGE(",
            "MIN(": "MIN(",
            "MAX(": "MAX(",
            "ISNULL(": "ISBLANK(",
            "LEN(": "LEN(",
            "TRIM(": "TRIM(",
            "UPPER(": "UPPER(",
            "LOWER(": "LOWER("
        }
        
        for tableau_func, dax_func in replacements.items():
            dax_formula = dax_formula.replace(tableau_func, dax_func)
        
        return dax_formula
    
    @classmethod
    def convert_to_bim(cls, tableau_data: Dict) -> Dict:
        """
        Convert Tableau data structure to BIM (Business Intelligence Model) format.
        
        Args:
            tableau_data: Parsed Tableau workbook data
            
        Returns:
            BIM model dictionary
        """
        tables = []
        
        # Convert data sources to tables
        for ds in tableau_data.get('datasources', []):
            if not ds.get('name') or ds['name'] in ['Parameters', 'Filters']:
                continue
                
            table_name = cls._sanitize_name(ds['name'])
            table = {
                "name": table_name,
                "columns": [],
                "partitions": [
                    {
                        "name": f"{table_name}_Partition",
                        "dataView": "full",
                        "source": {
                            "type": "m",
                            "expression": cls._generate_m_expression(ds)
                        }
                    }
                ]
            }
            
            # Add columns
            for field in ds.get('fields', []):
                if field.get('name') and not field['name'].startswith('[Parameters]'):
                    column_name = cls._sanitize_name(field['name'].replace('[', '').replace(']', ''))
                    if column_name:
                        column = {
                            "name": column_name,
                            "dataType": cls.map_datatype(field.get('datatype', 'string')),
                            "isHidden": False,
                            "sourceColumn": column_name
                        }
                        
                        # Add caption if available
                        if field.get('caption'):
                            column["displayName"] = field['caption']
                        
                        # Set column role
                        if field.get('role') == 'measure':
                            column["summarizeBy"] = "sum"
                        
                        table['columns'].append(column)
            
            # Ensure at least one column exists
            if not table['columns']:
                table['columns'].append({
                    "name": "DefaultColumn",
                    "dataType": "string",
                    "isHidden": True,
                    "sourceColumn": "DefaultColumn"
                })
            
            # Add measures from calculated fields
            measures = []
            for calc_field in tableau_data.get('calculated_fields', []):
                if calc_field.get('name'):
                    measure_name = cls._sanitize_name(calc_field['name'])
                    measure = {
                        "name": measure_name,
                        "expression": cls.convert_formula_to_dax(calc_field.get('formula', '')),
                        "isHidden": False,
                        "formatString": "0"
                    }
                    measures.append(measure)
            
            if measures:
                table['measures'] = measures
            
            tables.append(table)

        # Create dummy table if no tables found
        if not tables:
            tables.append({
                "name": "DummyTable",
                "columns": [
                    {
                        "name": "DummyColumn",
                        "dataType": "string",
                        "isHidden": False,
                        "sourceColumn": "DummyColumn"
                    }
                ],
                "partitions": [
                    {
                        "name": "DummyTable_Partition",
                        "dataView": "full",
                        "source": {
                            "type": "m",
                            "expression": [
                                "let",
                                "    Source = Table.FromRows(Json.Document(Binary.Decompress(Binary.FromText(\"\", BinaryEncoding.Base64), Compression.Deflate)), let _t = ((type nullable text) meta [Serialized.Text = true]) in type table [DummyColumn = _t]),",
                                "    #\"Changed Type\" = Table.TransformColumnTypes(Source,{{\"DummyColumn\", type text}})",
                                "in",
                                "    #\"Changed Type\""
                            ]
                        }
                    }
                ]
            })

        # Build complete BIM structure
        bim_model = {
            "name": "SemanticModel",
            "compatibilityLevel": 1550,
            "model": {
                "culture": "en-US",
                "dataAccessOptions": {
                    "legacyRedirects": True,
                    "returnErrorValuesAsNull": True
                },
                "defaultPowerBIDataSourceVersion": "powerBI_V3",
                "sourceQueryCulture": "en-US",
                "tables": tables,
                "annotations": [
                    {
                        "name": "TabularEditor_SerializeOptions",
                        "value": "{\"IgnoreInferredObjects\":false,\"IgnoreInferredProperties\":false,\"IgnoreTimestamps\":false,\"SplitMultilineStrings\":false,\"PrefixFilenames\":false,\"LocalTranslations\":false,\"LocalPerspectives\":false,\"LocalRelationships\":false,\"Levels\":[\"Data Sources\",\"Shared Expressions\",\"Perspectives\",\"Relationships\",\"Roles\",\"Tables\",\"Tables/Columns\",\"Tables/Hierarchies\",\"Tables/Measures\",\"Tables/Partitions\",\"Tables/Calculation Groups\",\"Translations\"]}"
                    },
                    {
                        "name": "PBI_QueryOrder", 
                        "value": json.dumps([table['name'] for table in tables])
                    }
                ]
            }
        }
        
        return bim_model
    
    @staticmethod
    def _sanitize_name(name: str) -> str:
        """Sanitize names for Power BI compatibility."""
        if not name:
            return ""
        return name.replace(" ", "_").replace("-", "_").replace(".", "_").replace("[", "").replace("]", "")
    
    @staticmethod
    def _generate_m_expression(datasource: Dict) -> List[str]:
        """Generate Power Query M expression for a data source."""
        # Basic M expression template
        return [
            "let",
            "    Source = Table.FromRows(Json.Document(Binary.Decompress(Binary.FromText(\"\", BinaryEncoding.Base64), Compression.Deflate)), let _t = ((type nullable text) meta [Serialized.Text = true]) in type table [Column1 = _t]),",
            "    #\"Changed Type\" = Table.TransformColumnTypes(Source,{{\"Column1\", type text}})",
            "in",
            "    #\"Changed Type\""
        ]


class PowerBIProjectWriter:
    """Handles writing Power BI project files (.pbixproj format)."""
    
    def __init__(self, output_dir: str):
        """
        Initialize the project writer.
        
        Args:
            output_dir: Directory to write project files
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def write_project_files(self, bim_model: Dict) -> str:
        """
        Write all required Power BI project files.
        
        Args:
            bim_model: BIM model dictionary
            
        Returns:
            Path to the project directory
        """
        logger.info("ðŸ“ Writing Power BI project files...")
        
        # Write all required files
        self._write_bim_model(bim_model)
        self._write_version_file()
        self._write_settings_file()
        self._write_metadata_file()
        self._write_connections_file()
        self._write_diagram_layout()
        self._write_report_layout()
        self._write_static_resources()
        self._write_report_metadata()
        self._write_security_bindings()
        self._write_report_settings()
        
        logger.info(f"âœ… Project files written to {self.output_dir}")
        return str(self.output_dir)
    
    def _write_bim_model(self, bim_model: Dict):
        """Write the BIM model file."""
        dms_dir = self.output_dir / "DataModelSchema"
        dms_dir.mkdir(exist_ok=True)
        
        bim_path = dms_dir / "Model.bim"
        with open(bim_path, 'w', encoding='utf-8') as f:
            json.dump(bim_model, f, indent=2)
        logger.debug(f"âœ… Saved BIM to {bim_path}")
    
    def _write_version_file(self):
        """Write Version.txt file."""
        version_path = self.output_dir / "Version.txt"
        with open(version_path, 'w', encoding='utf-8') as f:
            f.write("3.0")
        logger.debug(f"ðŸ“ Added {version_path}")
    
    def _write_settings_file(self):
        """Write Settings file."""
        settings_path = self.output_dir / "Settings"
        with open(settings_path, 'w', encoding='utf-8') as f:
            json.dump({}, f)
        logger.debug(f"ðŸ“ Added Settings file")
    
    def _write_metadata_file(self):
        """Write Metadata file."""
        metadata_path = self.output_dir / "Metadata"
        metadata = {
            "version": "3.0",
            "minVersion": "3.0"
        }
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f)
        logger.debug(f"ðŸ“ Added Metadata file")
    
    def _write_connections_file(self):
        """Write connections.json file."""
        dms_dir = self.output_dir / "DataModelSchema"
        dms_dir.mkdir(exist_ok=True)
        
        conn_path = dms_dir / "connections.json"
        with open(conn_path, 'w', encoding='utf-8') as f:
            json.dump([], f)
        logger.debug(f"ðŸ“ Added connections.json")
    
    def _write_diagram_layout(self):
        """Write DiagramLayout file."""
        dms_dir = self.output_dir / "DataModelSchema"
        dms_dir.mkdir(exist_ok=True)
        
        diagram_path = dms_dir / "DiagramLayout"
        diagram_layout = {
            "version": 1,
            "diagramLayouts": []
        }
        with open(diagram_path, 'w', encoding='utf-8') as f:
            json.dump(diagram_layout, f)
        logger.debug(f"ðŸ“ Added DiagramLayout")
    
    def _write_report_layout(self):
        """Write Report/Layout file."""
        report_dir = self.output_dir / "Report"
        report_dir.mkdir(exist_ok=True)
        
        layout_path = report_dir / "Layout"
        minimal_layout = {
            "id": 0,
            "resourcePackages": [],
            "config": "{\"version\":\"5.43\",\"themeCollection\":{\"baseTheme\":{\"name\":\"CY24SU06\"}}}",
            "layoutOptimization": 0
        }
        with open(layout_path, 'w', encoding='utf-8') as f:
            json.dump(minimal_layout, f)
        logger.debug(f"ðŸ“ Added Report/Layout")
    
    def _write_static_resources(self):
        """Write StaticResources.json file."""
        report_dir = self.output_dir / "Report"
        report_dir.mkdir(exist_ok=True)
        
        static_path = report_dir / "StaticResources.json"
        with open(static_path, 'w', encoding='utf-8') as f:
            json.dump({}, f)
        logger.debug(f"ðŸ“ Added StaticResources.json")
    
    def _write_report_metadata(self):
        """Write ReportMetadata.json file."""
        metadata_path = self.output_dir / "ReportMetadata.json"
        report_metadata = {
            "version": "3.0",
            "createdFromTemplate": False,
            "settings": {
                "useStylableVisualContainerHeader": True
            },
            "objects": {
                "section": [
                    {
                        "name": "ReportSection",
                        "displayName": "Page 1",
                        "visualContainers": []
                    }
                ]
            }
        }
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(report_metadata, f, indent=2)
        logger.debug(f"ðŸ“ Added ReportMetadata.json")
    
    def _write_security_bindings(self):
        """Write SecurityBindings.json file."""
        security_path = self.output_dir / "SecurityBindings.json"
        security_bindings = {
            "version": "3.0",
            "bindings": []
        }
        with open(security_path, 'w', encoding='utf-8') as f:
            json.dump(security_bindings, f)
        logger.debug(f"ðŸ“ Added SecurityBindings.json")
    
    def _write_report_settings(self):
        """Write ReportSettings.json file."""
        settings_path = self.output_dir / "ReportSettings.json"
        report_settings = {
            "name": "ReportSettings",
            "version": "3.0",
            "objects": {
                "ReportSettings": [
                    {
                        "name": "ReportSettings",
                        "properties": {
                            "defaultTheme": {
                                "name": "CY24SU06"
                            }
                        }
                    }
                ]
            }
        }
        with open(settings_path, 'w', encoding='utf-8') as f:
            json.dump(report_settings, f, indent=2)
        logger.debug(f"ðŸ“ Added ReportSettings.json")


class PBIToolsCompiler:
    """Handles compilation of Power BI project files using pbi-tools."""
    
    def __init__(self, auto_install: bool = True):
        """
        Initialize the compiler.
        
        Args:
            auto_install: Whether to automatically install pbi-tools if not found
        """
        self.auto_install = auto_install
        self.installer = PBIToolsInstaller()
    
    def ensure_pbi_tools_available(self) -> bool:
        """Ensure pbi-tools is available, installing if necessary."""
        installation_info = self.installer.check_installation()
        
        if installation_info["installed"]:
            logger.info(f"âœ… pbi-tools found: {installation_info['version']}")
            return True
        
        if not self.auto_install:
            logger.error("âŒ pbi-tools not found and auto-install is disabled")
            return False
        
        logger.info("ðŸ”§ pbi-tools not found. Starting auto-installation...")
        return self.installer.install_or_update()
    
    @staticmethod
    def is_pbi_tools_available() -> bool:
        """Check if pbi-tools is available in the system."""
        try:
            # pbi-tools doesn't support --version, but running it with no args
            # will show help and return exit code 1, which means it's available
            result = subprocess.run(["pbi-tools"], 
                                  capture_output=True, text=True, timeout=10)
            # Check if the output contains the expected pbi-tools signature
            return "pbi-tools" in result.stdout and "Copyright" in result.stdout
        except (FileNotFoundError, subprocess.TimeoutExpired):
            return False
        except Exception:
            # If any other exception occurs, assume it's not available
            return False
    
    def compile_to_pbit(self, project_dir: str, output_path: str, overwrite: bool = True) -> bool:
        """
        Compile Power BI project to .pbit file using pbi-tools.
        
        Args:
            project_dir: Path to the Power BI project directory
            output_path: Output path for the .pbit file
            overwrite: Whether to overwrite existing file
            
        Returns:
            True if compilation successful, False otherwise
        """
        # Ensure pbi-tools is available (auto-install if needed)
        if not self.ensure_pbi_tools_available():
            logger.error("âŒ pbi-tools is not available and could not be installed")
            logger.error("   Manual installation options:")
            logger.error("   Option 1: choco install pbi-tools")
            logger.error("   Option 2: Download from https://github.com/pbi-tools/pbi-tools/releases")
            return False
        
        # Check for version compatibility
        compatibility = handle_pbi_tools_compatibility()
        
        if not compatibility.get("compatible", True):
            logger.error(f"âŒ COMPATIBILITY ERROR: {compatibility.get('warning', 'Unknown compatibility issue')}")
            logger.error("ðŸ”§ SOLUTIONS:")
            logger.error("   1. Update pbi-tools to latest version")
            logger.error("   2. Use project files manually with Power BI Desktop")
            logger.error("   3. Use alternative compilation method")
            
            # Offer immediate solutions
            try:
                logger.info("\nðŸ”„ Available options:")
                logger.info("   [1] Try updating pbi-tools automatically")
                logger.info("   [2] Use manual compilation (recommended)")
                logger.info("   [3] Continue anyway (may fail)")
                
                choice = input("Choose option (1/2/3): ").strip()
                
                if choice == '1':
                    logger.info("ðŸ”„ Updating pbi-tools...")
                    if self.installer.install_or_update(force_reinstall=True):
                        logger.info("ðŸ”„ Retrying compilation...")
                        return self.compile_to_pbit(project_dir, output_path, overwrite)
                    else:
                        logger.error("âŒ Update failed")
                        return False
                
                elif choice == '2':
                    logger.info("ðŸ“‹ MANUAL COMPILATION INSTRUCTIONS:")
                    logger.info("   1. Open Power BI Desktop")
                    logger.info("   2. File â†’ Open â†’ Browse to:")
                    logger.info(f"      {project_dir}")
                    logger.info("   3. File â†’ Export â†’ Power BI Template (.pbit)")
                    logger.info(f"   4. Save as: {output_path}")
                    logger.info("   5. See PBI_TOOLS_GUIDE.md for detailed steps")
                    return True  # Consider manual compilation as success
                
                elif choice == '3':
                    logger.warning("âš ï¸  Proceeding despite compatibility issues...")
                else:
                    logger.info("âŒ Compilation cancelled")
                    return False
                    
            except (EOFError, KeyboardInterrupt):
                logger.info("âŒ Compilation cancelled")
                return False
        
        elif compatibility.get("warning"):
            logger.warning(f"âš ï¸  {compatibility['warning']}")
            logger.warning("   Compilation may fail due to version mismatch")
        
        logger.info("ðŸ—ï¸  Compiling .pbit using pbi-tools...")
        
        try:
            result = subprocess.run([
                "pbi-tools", "compile",
                project_dir,
                output_path,
                "PBIT",
                str(overwrite)
            ], capture_output=True, text=True, check=True)
            
            logger.info(f"âœ… .pbit created at: {output_path}")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error("âŒ Error creating .pbit:")
            logger.error(f"STDOUT: {e.stdout}")
            logger.error(f"STDERR: {e.stderr}")
            
            # Enhanced error detection and handling
            error_messages = []
            
            if "MissingMethodException" in e.stderr:
                error_messages.append("ðŸ”§ METHOD NOT FOUND ERROR:")
                error_messages.append("   This is a version compatibility issue between pbi-tools and Power BI Desktop")
                error_messages.append(f"   Your Power BI Desktop version: {compatibility.get('current_pbi_version', 'unknown')}")
                error_messages.append(f"   Your pbi-tools version: {compatibility.get('pbi_tools_version', 'unknown')}")
                error_messages.append("   The PowerBIPackager.Save method signature has changed")
            
            elif "Method not found" in e.stderr:
                error_messages.append("ðŸ”§ API COMPATIBILITY ERROR:")
                error_messages.append("   Power BI Desktop API has changed since this pbi-tools version was built")
            
            elif "Access denied" in e.stderr or "permission" in e.stderr.lower():
                error_messages.append("ðŸ”§ PERMISSION ERROR:")
                error_messages.append("   Try running as administrator")
                error_messages.append("   Check if output directory is writable")
            
            elif "not found" in e.stderr.lower():
                error_messages.append("ðŸ”§ FILE NOT FOUND ERROR:")
                error_messages.append("   Check if all required files are in the project directory")
            
            else:
                error_messages.append("ðŸ”§ UNKNOWN ERROR:")
                error_messages.append("   See error details above")
            
            for msg in error_messages:
                logger.error(msg)
            
            logger.error("\nðŸ’¡ RECOMMENDED SOLUTIONS:")
            logger.error("   1. Use manual compilation (most reliable):")
            logger.error("      â€¢ Open Power BI Desktop")
            logger.error(f"      â€¢ File â†’ Open â†’ {project_dir}")
            logger.error("      â€¢ File â†’ Export â†’ Power BI Template (.pbit)")
            logger.error("   2. Update both pbi-tools and Power BI Desktop")
            logger.error("   3. Check GitHub issues: https://github.com/pbi-tools/pbi-tools/issues")
            
            # Offer to open project directory
            try:
                open_choice = input("\nWould you like to open the project directory for manual compilation? (y/n): ").lower().strip()
                if open_choice == 'y':
                    import subprocess
                    import platform
                    
                    if platform.system() == "Windows":
                        subprocess.run(["explorer", project_dir])
                    elif platform.system() == "Darwin":  # macOS
                        subprocess.run(["open", project_dir])
                    else:  # Linux
                        subprocess.run(["xdg-open", project_dir])
                    
                    logger.info(f"ðŸ“‚ Opened project directory: {project_dir}")
                    
            except (EOFError, KeyboardInterrupt):
                pass
                
            return False


class PBIToolsInstaller:
    """Handles automatic installation and updates of pbi-tools."""
    
    def __init__(self):
        self.github_repo = "pbi-tools/pbi-tools"
        self.api_url = f"https://api.github.com/repos/{self.github_repo}/releases/latest"
        self.install_dir = Path.home() / ".pbi-tools"
        self.bin_dir = self.install_dir / "bin"
        
    def check_installation(self) -> Dict:
        """Check if pbi-tools is installed and get version info."""
        try:
            result = subprocess.run(["pbi-tools"], 
                                  capture_output=True, text=True, timeout=10)
            # pbi-tools shows help when run without args
            if "pbi-tools" in result.stdout and "Copyright" in result.stdout:
                # Try to get version info
                version_info = self._get_version_info()
                return {
                    "installed": True,
                    "version": version_info.get("version", "unknown"),
                    "path": self._find_pbi_tools_path()
                }
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        return {"installed": False, "version": None, "path": None}
    
    def _get_version_info(self) -> Dict:
        """Get detailed version information from pbi-tools."""
        try:
            result = subprocess.run(["pbi-tools", "info"], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                return json.loads(result.stdout)
        except Exception:
            pass
        return {"version": "unknown"}
    
    def _find_pbi_tools_path(self) -> Optional[str]:
        """Find the path where pbi-tools is installed."""
        try:
            if platform.system() == "Windows":
                result = subprocess.run(["where", "pbi-tools"], 
                                      capture_output=True, text=True)
            else:
                result = subprocess.run(["which", "pbi-tools"], 
                                      capture_output=True, text=True)
            
            if result.returncode == 0:
                return result.stdout.strip().split('\n')[0]
        except Exception:
            pass
        return None
    
    def get_latest_version_info(self) -> Dict:
        """Get information about the latest pbi-tools release from GitHub."""
        try:
            logger.info("ðŸ” Checking for latest pbi-tools version...")
            response = requests.get(self.api_url, timeout=10)
            response.raise_for_status()
            
            release_data = response.json()
            version = release_data["tag_name"].lstrip("v")
            
            # Find the appropriate asset for current platform
            system = platform.system().lower()
            arch = "x64" if platform.machine().endswith('64') else "x86"
            
            download_url = None
            filename = None
            
            for asset in release_data["assets"]:
                asset_name = asset["name"].lower()
                if system == "windows" and f"win-{arch}" in asset_name and asset_name.endswith(".zip"):
                    download_url = asset["browser_download_url"]
                    filename = asset["name"]
                    break
                elif system == "linux" and f"linux-{arch}" in asset_name and asset_name.endswith(".tar.gz"):
                    download_url = asset["browser_download_url"]
                    filename = asset["name"]
                    break
                elif system == "darwin" and "osx" in asset_name:
                    download_url = asset["browser_download_url"]
                    filename = asset["name"]
                    break
            
            return {
                "version": version,
                "download_url": download_url,
                "filename": filename,
                "release_notes": release_data.get("body", "")
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to get latest version info: {e}")
            return {}
    
    def download_pbi_tools(self, download_url: str, filename: str) -> Path:
        """Download pbi-tools from GitHub releases."""
        logger.info(f"â¬‡ï¸  Downloading pbi-tools: {filename}")
        
        self.install_dir.mkdir(exist_ok=True)
        download_path = self.install_dir / filename
        
        try:
            response = requests.get(download_url, stream=True, timeout=30)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            with open(download_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # Simple progress indicator
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            if downloaded % (1024 * 1024) == 0:  # Every MB
                                logger.info(f"ðŸ“¥ Downloaded: {progress:.1f}%")
            
            logger.info(f"âœ… Download completed: {download_path}")
            return download_path
            
        except Exception as e:
            logger.error(f"âŒ Download failed: {e}")
            if download_path.exists():
                download_path.unlink()
            raise
    
    def extract_and_install(self, archive_path: Path, version: str):
        """Extract and install pbi-tools."""
        logger.info(f"ðŸ“¦ Extracting pbi-tools {version}...")
        
        # Remove old installation
        if self.bin_dir.exists():
            shutil.rmtree(self.bin_dir)
        
        self.bin_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            if archive_path.suffix == '.zip':
                import zipfile
                with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                    zip_ref.extractall(self.bin_dir)
            elif archive_path.suffix == '.gz':
                import tarfile
                with tarfile.open(archive_path, 'r:gz') as tar_ref:
                    tar_ref.extractall(self.bin_dir)
            
            # Make executable on Unix-like systems
            if platform.system() != "Windows":
                pbi_tools_exe = self.bin_dir / "pbi-tools"
                if pbi_tools_exe.exists():
                    pbi_tools_exe.chmod(0o755)
            
            # Add to PATH
            self._add_to_path()
            
            # Clean up archive
            archive_path.unlink()
            
            logger.info(f"âœ… pbi-tools {version} installed successfully!")
            logger.info(f"ðŸ“‚ Installation directory: {self.bin_dir}")
            
        except Exception as e:
            logger.error(f"âŒ Extraction failed: {e}")
            raise
    
    def _add_to_path(self):
        """Add pbi-tools to system PATH."""
        bin_str = str(self.bin_dir)
        
        if platform.system() == "Windows":
            # Windows PATH update
            current_path = os.environ.get('PATH', '')
            if bin_str not in current_path:
                os.environ['PATH'] = f"{bin_str};{current_path}"
                
                # Try to update user PATH permanently
                try:
                    # Get current user PATH
                    result = subprocess.run([
                        'reg', 'query', 'HKCU\\Environment', '/v', 'PATH'
                    ], capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        # Extract current PATH value
                        for line in result.stdout.split('\n'):
                            if 'PATH' in line and 'REG_' in line:
                                current_user_path = line.split('REG_SZ')[-1].strip()
                                if bin_str not in current_user_path:
                                    new_path = f"{bin_str};{current_user_path}"
                                    subprocess.run([
                                        'setx', 'PATH', new_path
                                    ], check=True, capture_output=True)
                                    logger.info("âœ… PATH updated permanently")
                                break
                    else:
                        # No existing PATH, create one
                        subprocess.run([
                            'setx', 'PATH', bin_str
                        ], check=True, capture_output=True)
                        logger.info("âœ… PATH created and updated")
                        
                except subprocess.CalledProcessError:
                    logger.warning("âš ï¸  Could not permanently update PATH. You may need to restart your terminal.")
        
        else:
            # Unix-like systems
            shell_configs = [
                Path.home() / ".bashrc",
                Path.home() / ".bash_profile", 
                Path.home() / ".zshrc",
                Path.home() / ".profile"
            ]
            
            path_export = f'export PATH="{bin_str}:$PATH"'
            added_to_config = False
            
            for config_file in shell_configs:
                if config_file.exists():
                    content = config_file.read_text()
                    if bin_str not in content:
                        with open(config_file, 'a') as f:
                            f.write(f"\n# pbi-tools\n{path_export}\n")
                        logger.info(f"âœ… Added to {config_file}")
                        added_to_config = True
                        break
            
            if not added_to_config:
                # Create .bashrc if none exist
                bashrc = Path.home() / ".bashrc"
                with open(bashrc, 'w') as f:
                    f.write(f"# pbi-tools\n{path_export}\n")
                logger.info(f"âœ… Created {bashrc} with PATH")
    
    def install_or_update(self, force_reinstall: bool = False) -> bool:
        """Main method to install or update pbi-tools."""
        try:
            # Check current installation
            current_install = self.check_installation()
            
            # Get latest version info
            latest_info = self.get_latest_version_info()
            if not latest_info.get("download_url"):
                logger.error("âŒ Could not find download for current platform")
                return False
            
            latest_version = latest_info["version"]
            
            # Decide whether to install/update
            if current_install["installed"] and not force_reinstall:
                current_version = current_install["version"]
                logger.info(f"ðŸ“¦ Current version: {current_version}")
                logger.info(f"ðŸ†• Latest version: {latest_version}")
                
                if current_version == latest_version:
                    logger.info("âœ… pbi-tools is already up to date!")
                    return True
                
                logger.info(f"ðŸ”„ Update available: {current_version} â†’ {latest_version}")
                if not force_reinstall:
                    try:
                        choice = input("Would you like to update? (y/n): ").lower().strip()
                        if choice != 'y':
                            logger.info("â­ï¸  Update skipped")
                            return True
                    except (EOFError, KeyboardInterrupt):
                        logger.info("â­ï¸  Update skipped")
                        return True
            
            # Perform installation/update
            logger.info(f"ðŸš€ Installing pbi-tools {latest_version}...")
            
            # Download
            archive_path = self.download_pbi_tools(
                latest_info["download_url"], 
                latest_info["filename"]
            )
            
            # Extract and install
            self.extract_and_install(archive_path, latest_version)
            
            # Verify installation
            verification = self.check_installation()
            if verification["installed"]:
                logger.info("ðŸŽ‰ Installation completed successfully!")
                logger.info("ðŸ’¡ You may need to restart your terminal/IDE for PATH changes to take effect")
                return True
            else:
                logger.error("âŒ Installation verification failed")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Installation failed: {e}")
            return False
    
    def uninstall(self) -> bool:
        """Uninstall pbi-tools."""
        try:
            if self.install_dir.exists():
                shutil.rmtree(self.install_dir)
                logger.info("âœ… pbi-tools uninstalled successfully")
                logger.info("ðŸ’¡ You may need to manually remove PATH entries")
                return True
            else:
                logger.info("â„¹ï¸  pbi-tools is not installed in the default location")
                return True
        except Exception as e:
            logger.error(f"âŒ Uninstall failed: {e}")
            return False


def auto_install_pbi_tools(force_reinstall: bool = False) -> bool:
    """Convenience function for auto-installing pbi-tools."""
    installer = PBIToolsInstaller()
    return installer.install_or_update(force_reinstall)


class TableauToPowerBIConverter:
    """Main converter class that orchestrates the conversion process."""
    
    def __init__(self, temp_dir: Optional[str] = None, auto_install_pbi_tools: bool = True):
        """
        Initialize the converter.
        
        Args:
            temp_dir: Temporary directory for intermediate files (auto-created if None)
            auto_install_pbi_tools: Whether to automatically install pbi-tools if not found
        """
        self.temp_dir = temp_dir or tempfile.mkdtemp(prefix="tb2pbi_")
        self.extractor = TableauExtractor()
        self.converter = PowerBIConverter()
        self.compiler = PBIToolsCompiler(auto_install=auto_install_pbi_tools)
    
    def convert(self, 
                twbx_path: str, 
                output_path: str, 
                project_dir: Optional[str] = None,
                cleanup_temp: bool = True) -> bool:
        """
        Convert a Tableau workbook to Power BI template.
        
        Args:
            twbx_path: Path to the Tableau workbook (.twbx)
            output_path: Path for the output Power BI template (.pbit)
            project_dir: Directory for intermediate project files (uses temp if None)
            cleanup_temp: Whether to cleanup temporary files
            
        Returns:
            True if conversion successful, False otherwise
        """
        try:
            logger.info("ðŸš€ Starting Tableau to Power BI conversion...")
            
            # Step 1: Extract and parse Tableau workbook
            logger.info("ðŸ“‚ Extracting Tableau workbook...")
            extracted_dir = self.extractor.extract_twbx(twbx_path)
            
            twb_file = self.extractor.find_twb_file(extracted_dir)
            tableau_data = self.extractor.parse_twb(twb_file)
            
            # Step 2: Convert to Power BI format
            logger.info("ðŸ”„ Converting to Power BI format...")
            bim_model = self.converter.convert_to_bim(tableau_data)
            
            # Step 3: Write project files
            if project_dir is None:
                project_dir = os.path.join(self.temp_dir, "pbix_project")
            
            writer = PowerBIProjectWriter(project_dir)
            project_path = writer.write_project_files(bim_model)
            
            # Step 4: Compile to .pbit
            logger.info("ðŸ”¨ Compiling to .pbit...")
            success = self.compiler.compile_to_pbit(project_path, output_path)
            
            if success:
                logger.info("ðŸŽ‰ Conversion completed successfully!")
                logger.info(f"ðŸ“ Output file: {output_path}")
                logger.info(f"ðŸ“‚ Project folder: {project_path}")
            else:
                logger.warning("âš ï¸  .pbit compilation failed, but project files are ready!")
                logger.info("ðŸ“‚ Manual compilation options:")
                logger.info("   1. Open Power BI Desktop")
                logger.info("   2. File â†’ Open â†’ Browse to the project folder:")
                logger.info(f"      {project_path}")
                logger.info("   3. File â†’ Export â†’ Power BI Template (.pbit)")
                logger.info("   4. See MANUAL_COMPILATION_GUIDE.md for detailed steps")
                # Still return success since project files were created
                success = True
            
            # Cleanup
            if cleanup_temp and extracted_dir.startswith(tempfile.gettempdir()):
                shutil.rmtree(extracted_dir, ignore_errors=True)
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ Conversion failed: {e}")
            return False
    
    def get_tableau_info(self, twbx_path: str) -> Dict:
        """
        Get information about a Tableau workbook without converting.
        
        Args:
            twbx_path: Path to the Tableau workbook (.twbx)
            
        Returns:
            Dictionary containing workbook information
        """
        try:
            extracted_dir = self.extractor.extract_twbx(twbx_path)
            twb_file = self.extractor.find_twb_file(extracted_dir)
            tableau_data = self.extractor.parse_twb(twb_file)
            
            # Cleanup
            if extracted_dir.startswith(tempfile.gettempdir()):
                shutil.rmtree(extracted_dir, ignore_errors=True)
            
            return tableau_data
            
        except Exception as e:
            raise TableauToPowerBIError(f"Failed to analyze Tableau workbook: {e}")


# Convenience functions for direct usage
def convert_tableau_to_powerbi(twbx_path: str, 
                              output_path: str, 
                              project_dir: Optional[str] = None,
                              auto_install_pbi_tools: bool = True) -> bool:
    """
    Convert a Tableau workbook to Power BI template (convenience function).
    
    Args:
        twbx_path: Path to the Tableau workbook (.twbx)
        output_path: Path for the output Power BI template (.pbit)
        project_dir: Directory for intermediate project files (optional)
        auto_install_pbi_tools: Whether to automatically install pbi-tools if needed
        
    Returns:
        True if conversion successful, False otherwise
    """
    converter = TableauToPowerBIConverter(auto_install_pbi_tools=auto_install_pbi_tools)
    return converter.convert(twbx_path, output_path, project_dir)


def analyze_tableau_workbook(twbx_path: str) -> Dict:
    """
    Analyze a Tableau workbook and return its structure (convenience function).
    
    Args:
        twbx_path: Path to the Tableau workbook (.twbx)
        
    Returns:
        Dictionary containing workbook information
    """
    converter = TableauToPowerBIConverter()
    return converter.get_tableau_info(twbx_path)


def handle_pbi_tools_compatibility():
    """Check pbi-tools compatibility and provide guidance"""
    try:
        result = subprocess.run(["pbi-tools", "info"], 
                              capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            import json
            info = json.loads(result.stdout)
            
            pbi_tools_version = info.get("version", "unknown")
            pbi_build_version = info.get("pbiBuildVersion", "unknown")
            
            # Check if there are PBI installs
            pbi_installs = info.get("pbiInstalls", [])
            if pbi_installs:
                current_pbi_version = pbi_installs[0].get("ProductVersion", "unknown")
                
                # Parse version numbers for comparison
                def parse_version(version_str):
                    try:
                        # Extract major.minor.build from version string
                        parts = version_str.split('.')
                        return tuple(int(x) for x in parts[:3])
                    except:
                        return (0, 0, 0)
                
                expected_version = parse_version(pbi_build_version)
                actual_version = parse_version(current_pbi_version)
                
                # Check for known incompatible combinations
                is_compatible = True
                warning_message = None
                
                # Your specific case: PBI Desktop 2.144.1155.0 with older pbi-tools
                if actual_version >= (2, 144, 0) and pbi_tools_version.startswith("1."):
                    is_compatible = False
                    warning_message = (
                        f"INCOMPATIBLE: Power BI Desktop {current_pbi_version} requires pbi-tools 2.x+, "
                        f"but you have pbi-tools {pbi_tools_version}. "
                        "The 'PowerBIPackager.Save' method signature changed in newer PBI versions."
                    )
                elif expected_version != actual_version:
                    warning_message = (
                        f"Version mismatch: pbi-tools expects {pbi_build_version}, "
                        f"found {current_pbi_version}. This may cause compilation issues."
                    )
                
                return {
                    "compatible": is_compatible,
                    "pbi_tools_version": pbi_tools_version,
                    "pbi_build_version": pbi_build_version,
                    "current_pbi_version": current_pbi_version,
                    "warning": warning_message,
                    "expected_version": expected_version,
                    "actual_version": actual_version
                }
            
        return {"compatible": False, "error": "Could not determine versions"}
        
    except Exception as e:
        return {"compatible": False, "error": str(e)}


if __name__ == "__main__":
    # Enhanced CLI with pbi-tools management
    import argparse
    
    parser = argparse.ArgumentParser(description='Tableau to Power BI Converter')
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Convert command
    convert_parser = subparsers.add_parser('convert', help='Convert Tableau workbook to Power BI')
    convert_parser.add_argument('input', help='Input Tableau file (.twbx)')
    convert_parser.add_argument('output', help='Output Power BI file (.pbit)')
    convert_parser.add_argument('--project-dir', help='Directory for intermediate project files')
    convert_parser.add_argument('--no-auto-install', action='store_true', 
                               help='Disable automatic pbi-tools installation')
    
    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', help='Analyze Tableau workbook structure')
    analyze_parser.add_argument('input', help='Input Tableau file (.twbx)')
    analyze_parser.add_argument('--output', help='Output JSON file for analysis results')
    
    # pbi-tools management commands
    pbi_parser = subparsers.add_parser('pbi-tools', help='Manage pbi-tools installation')
    pbi_subparsers = pbi_parser.add_subparsers(dest='pbi_command', help='pbi-tools commands')
    
    pbi_subparsers.add_parser('install', help='Install pbi-tools')
    pbi_subparsers.add_parser('update', help='Update pbi-tools to latest version')
    pbi_subparsers.add_parser('status', help='Check pbi-tools installation status')
    pbi_subparsers.add_parser('uninstall', help='Uninstall pbi-tools')
    
    # Force reinstall option
    install_parser = pbi_subparsers.add_parser('reinstall', help='Force reinstall pbi-tools')
    
    args = parser.parse_args()
    
    if not args.command:
        # Default behavior for backward compatibility
        if len(sys.argv) >= 3:
            input_file = sys.argv[1]
            output_file = sys.argv[2]
            success = convert_tableau_to_powerbi(input_file, output_file)
            sys.exit(0 if success else 1)
        else:
            parser.print_help()
            sys.exit(1)
    
    elif args.command == 'convert':
        auto_install = not args.no_auto_install
        success = convert_tableau_to_powerbi(
            args.input, 
            args.output, 
            args.project_dir,
            auto_install_pbi_tools=auto_install
        )
        sys.exit(0 if success else 1)
    
    elif args.command == 'analyze':
        try:
            analysis = analyze_tableau_workbook(args.input)
            
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, indent=2)
                print(f"âœ… Analysis saved to: {args.output}")
            else:
                print(json.dumps(analysis, indent=2))
            
        except Exception as e:
            print(f"âŒ Analysis failed: {e}")
            sys.exit(1)
    
    elif args.command == 'pbi-tools':
        installer = PBIToolsInstaller()
        
        if args.pbi_command == 'install':
            success = installer.install_or_update()
            sys.exit(0 if success else 1)
        
        elif args.pbi_command == 'update':
            success = installer.install_or_update()
            sys.exit(0 if success else 1)
        
        elif args.pbi_command == 'reinstall':
            success = installer.install_or_update(force_reinstall=True)
            sys.exit(0 if success else 1)
        
        elif args.pbi_command == 'status':
            install_info = installer.check_installation()
            if install_info["installed"]:
                print(f"âœ… pbi-tools is installed")
                print(f"   Version: {install_info['version']}")
                print(f"   Path: {install_info['path']}")
                
                # Check for updates
                latest_info = installer.get_latest_version_info()
                if latest_info and latest_info.get("version"):
                    if install_info["version"] != latest_info["version"]:
                        print(f"ðŸ†• Update available: {install_info['version']} â†’ {latest_info['version']}")
                    else:
                        print("âœ… Up to date")
            else:
                print("âŒ pbi-tools is not installed")
                print("ðŸ’¡ Run 'python tableau_to_powerbi.py pbi-tools install' to install")
        
        elif args.pbi_command == 'uninstall':
            success = installer.uninstall()
            sys.exit(0 if success else 1)
        
        else:
            pbi_parser.print_help()
            sys.exit(1)
    
    else:
        parser.print_help()
        sys.exit(1)

class AlternativeCompilers:
    """Alternative compilation methods that don't require pbi-tools."""
    
    def __init__(self, project_dir: str, output_path: str):
        self.project_dir = Path(project_dir)
        self.output_path = Path(output_path)
        self.temp_dir = Path("temp_compilation")
        self.temp_dir.mkdir(exist_ok=True)
        
    def compile_with_tabular_editor(self) -> bool:
        """
        Use Tabular Editor to compile the model.
        Tabular Editor can work with .bim files directly.
        """
        logger.info("ðŸ”§ Attempting compilation with Tabular Editor...")
        
        # Check for Tabular Editor 2 (free version) and 3 (paid version)
        tabular_paths = [
            # Tabular Editor 2 (free)
            r"C:\Program Files (x86)\Tabular Editor\TabularEditor.exe",
            r"C:\Program Files\Tabular Editor\TabularEditor.exe",
            r"C:\Users\{}\AppData\Local\TabularEditor\TabularEditor.exe".format(os.environ.get('USERNAME', '')),
            # Tabular Editor 3 (paid)
            r"C:\Program Files\Tabular Editor 3\TabularEditor3.exe",
            r"C:\Program Files (x86)\Tabular Editor 3\TabularEditor3.exe",
            # Portable versions
            r".\TabularEditor.exe",
            r".\TabularEditor3.exe"
        ]
        
        tabular_exe = None
        for path in tabular_paths:
            if Path(path).exists():
                tabular_exe = path
                break
        
        if not tabular_exe:
            logger.warning("âŒ Tabular Editor not found")
            logger.info("ðŸ’¡ Install Tabular Editor 2 (free) from: https://tabulareditor.com/")
            logger.info("ðŸ’¡ Or download portable version to current directory")
            return False
        
        try:
            bim_file = self.project_dir / "DataModelSchema" / "Model.bim"
            if not bim_file.exists():
                logger.error(f"âŒ Model.bim not found at {bim_file}")
                return False
            
            # Create a comprehensive script for Tabular Editor
            script_content = f'''
// Tabular Editor C# script for PBIT compilation
try {{
    // Load the model
    Model.Database.Name = "{self.output_path.stem}";
    
    // Validate the model
    if (Model.Tables.Count == 0) {{
        Warning("Model has no tables");
    }}
    
    // Save as Power BI Template
    var pbitPath = @"{self.output_path.as_posix()}";
    
    // Ensure output directory exists
    var outputDir = System.IO.Path.GetDirectoryName(pbitPath);
    if (!System.IO.Directory.Exists(outputDir)) {{
        System.IO.Directory.CreateDirectory(outputDir);
    }}
    
    // Save the PBIT file
    SaveFile(pbitPath, SaveFormat.PowerBITemplate);
    
    Info("Successfully saved PBIT to: " + pbitPath);
}} catch (Exception ex) {{
    Error("Compilation failed: " + ex.Message);
}}
'''
            
            script_file = self.temp_dir / "tabular_compile_script.cs"
            with open(script_file, 'w', encoding='utf-8') as f:
                f.write(script_content)
            
            logger.info(f"ðŸ“ Created Tabular Editor script: {script_file}")
            
            # Run Tabular Editor with the script
            cmd = [tabular_exe, str(bim_file), "-S", str(script_file)]
            logger.info(f"ðŸƒ Running: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                if self.output_path.exists():
                    logger.info(f"âœ… Successfully compiled with Tabular Editor: {self.output_path}")
                    return True
                else:
                    logger.warning("âš ï¸  Tabular Editor completed but PBIT file not found")
                    logger.info(f"STDOUT: {result.stdout}")
                    return False
            else:
                logger.error(f"âŒ Tabular Editor compilation failed (return code: {result.returncode})")
                logger.error(f"STDOUT: {result.stdout}")
                logger.error(f"STDERR: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ Tabular Editor compilation timed out (5 minutes)")
            return False
        except Exception as e:
            logger.error(f"âŒ Tabular Editor compilation error: {e}")
            return False
        finally:
            # Cleanup script file
            if 'script_file' in locals():
                script_file.unlink(missing_ok=True)
    
    def compile_with_power_bi_desktop(self) -> bool:
        """
        Use Power BI Desktop directly via automation.
        This opens PBI Desktop and attempts to automate the save process.
        """
        logger.info("ðŸ”§ Attempting compilation with Power BI Desktop automation...")
        
        # Find Power BI Desktop installation
        pbi_paths = [
            r"C:\Program Files\Microsoft Power BI Desktop\bin\PBIDesktop.exe",
            r"C:\Program Files (x86)\Microsoft Power BI Desktop\bin\PBIDesktop.exe"
        ]
        
        # Check Windows Apps installation
        winapp_base = Path(r"C:\Program Files\WindowsApps")
        if winapp_base.exists():
            pbi_apps = list(winapp_base.glob("Microsoft.MicrosoftPowerBIDesktop_*/bin/PBIDesktop.exe"))
            pbi_paths.extend([str(p) for p in pbi_apps])
        
        pbi_exe = None
        for path in pbi_paths:
            if Path(path).exists():
                pbi_exe = path
                break
        
        if not pbi_exe:
            logger.warning("âŒ Power BI Desktop not found")
            return False
        
        try:
            logger.info("ðŸ“‹ Starting Power BI Desktop for manual compilation...")
            logger.info("ðŸ‘‰ MANUAL STEPS REQUIRED:")
            logger.info("   1. Power BI Desktop will open")
            logger.info("   2. File â†’ Open â†’ Browse to project folder")
            logger.info(f"   3. Select: {self.project_dir}")
            logger.info("   4. File â†’ Export â†’ Power BI Template (.pbit)")
            logger.info(f"   5. Save as: {self.output_path}")
            
            # Open Power BI Desktop
            subprocess.Popen([pbi_exe])
            
            # Try to open file explorer to the project directory
            if platform.system() == "Windows":
                subprocess.Popen(["explorer", str(self.project_dir)])
            
            logger.info("ðŸ’¡ Power BI Desktop and project folder opened")
            logger.info("ðŸ’¡ Complete the manual steps above to finish compilation")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Power BI Desktop automation error: {e}")
            return False
    
    def compile_with_sqlcmd_and_xmla(self) -> bool:
        """
        Use SQL Server Analysis Services (SSAS) to process the model.
        This requires SSAS to be installed locally.
        """
        logger.info("ðŸ”§ Attempting compilation with SSAS/XMLA...")
        
        # Check for SQL Server Analysis Services
        ssas_paths = [
            r"C:\Program Files\Microsoft SQL Server\*\Tools\Binn\SQLCMD.exe",
            r"C:\Program Files (x86)\Microsoft SQL Server\*\Tools\Binn\SQLCMD.exe"
        ]
        
        sqlcmd_exe = None
        for pattern in ssas_paths:
            matches = list(Path("/").glob(pattern.replace("C:\\", "")))
            if matches:
                sqlcmd_exe = str(matches[0])
                break
        
        if not sqlcmd_exe:
            logger.warning("âŒ SQL Server tools not found")
            logger.info("ðŸ’¡ This method requires SQL Server Management Studio or SQL Server tools")
            return False
        
        logger.info("ðŸ’¡ SSAS/XMLA method requires manual setup:")
        logger.info("   1. Deploy model to local SSAS instance")
        logger.info("   2. Use Power BI Desktop to connect to SSAS")
        logger.info("   3. Export as .pbit template")
        logger.info("ðŸ’¡ This is an advanced method - consider other options first")
        
        return False
    
    def compile_with_analysis_services_deployment_utility(self) -> bool:
        """
        Use Microsoft SQL Server Analysis Services Deployment Utility.
        This is part of SQL Server Data Tools (SSDT).
        """
        logger.info("ðŸ”§ Attempting compilation with Analysis Services Deployment Utility...")
        
        # Look for Analysis Services deployment tools
        asdeployment_paths = [
            r"C:\Program Files (x86)\Microsoft SQL Server\*\Tools\Binn\ManagementStudio\Microsoft.AnalysisServices.Deployment.exe",
            r"C:\Program Files\Microsoft SQL Server\*\Tools\Binn\ManagementStudio\Microsoft.AnalysisServices.Deployment.exe",
            r"C:\Program Files (x86)\Microsoft SQL Server\*\SSDT\Binn\Microsoft.AnalysisServices.Deployment.exe",
            r"C:\Program Files\Microsoft SQL Server\*\SSDT\Binn\Microsoft.AnalysisServices.Deployment.exe"
        ]
        
        asdeployment_exe = None
        for pattern in asdeployment_paths:
            # Use glob to handle wildcards in paths
            base_path = pattern.split("*")[0]
            if Path(base_path).exists():
                matches = list(Path(base_path).parent.glob(pattern.split("*")[1]))
                if matches:
                    for match in matches:
                        if match.name == "Microsoft.AnalysisServices.Deployment.exe":
                            asdeployment_exe = str(match)
                            break
                    if asdeployment_exe:
                        break
        
        if not asdeployment_exe:
            logger.warning("âŒ Analysis Services Deployment Utility not found")
            logger.info("ðŸ’¡ Install SQL Server Data Tools (SSDT) to get AS deployment tools")
            return False
        
        try:
            # Create deployment files for Analysis Services
            bim_file = self.project_dir / "DataModelSchema" / "Model.bim"
            if not bim_file.exists():
                logger.error(f"âŒ Model.bim not found at {bim_file}")
                return False
            
            # Analysis Services method requires manual deployment
            logger.info("ðŸ’¡ Analysis Services method requires these manual steps:")
            logger.info("   1. Deploy model to local Analysis Services instance")
            logger.info("   2. Connect Power BI Desktop to the AS database")
            logger.info("   3. Export as .pbit template")
            logger.info("ðŸ’¡ This is an advanced method - consider other options first")
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ Analysis Services compilation error: {e}")
            return False
    
    def compile_with_fabric_api(self) -> bool:
        """
        Use Microsoft Fabric REST APIs to process the model.
        This requires authentication and a Fabric workspace.
        """
        logger.info("ðŸ”§ Attempting compilation with Microsoft Fabric API...")
        
        try:
            # Check if user has Fabric credentials configured
            logger.info("ðŸ’¡ Microsoft Fabric API method requires:")
            logger.info("   1. Active Microsoft Fabric subscription")
            logger.info("   2. Authentication (Azure AD)")
            logger.info("   3. Fabric workspace access")
            logger.info("   4. REST API integration")
            logger.info("ðŸ’¡ This is a cloud-based method - consider other options for local compilation")
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ Fabric API compilation error: {e}")
            return False
    
    def compile_with_powerbi_cmdlets(self) -> bool:
        """
        Use PowerBI PowerShell cmdlets for compilation.
        This requires the MicrosoftPowerBIMgmt PowerShell module.
        """
        logger.info("ðŸ”§ Attempting compilation with PowerBI PowerShell cmdlets...")
        
        try:
            # Check if PowerShell is available
            powershell_exe = "powershell.exe"
            if platform.system() == "Windows":
                # Check for PowerShell installation
                result = subprocess.run([powershell_exe, "-Command", "Get-Module -ListAvailable MicrosoftPowerBIMgmt"], 
                                      capture_output=True, text=True, timeout=30)
                
                if "MicrosoftPowerBIMgmt" not in result.stdout:
                    logger.warning("âŒ MicrosoftPowerBIMgmt PowerShell module not found")
                    logger.info("ðŸ’¡ Install with: Install-Module -Name MicrosoftPowerBIMgmt")
                    return False
                
                # Create PowerShell script for PBIT compilation
                ps_script = f'''
# PowerBI PowerShell compilation script
Import-Module MicrosoftPowerBIMgmt

try {{
    # This would require authentication and cloud processing
    Write-Host "PowerBI PowerShell cmdlets require cloud authentication"
    Write-Host "This method is primarily for managing online Power BI content"
    Write-Host "For local PBIT creation, use other methods like Tabular Editor"
    
    # Connect-PowerBIServiceAccount would be needed here
    # But local PBIT creation is not directly supported
    
    exit 1
}} catch {{
    Write-Error "PowerBI cmdlets compilation failed: $($_.Exception.Message)"
    exit 1
}}
'''
                
                script_file = self.temp_dir / "powerbi_compile.ps1"
                with open(script_file, 'w', encoding='utf-8') as f:
                    f.write(ps_script)
                
                logger.info("ðŸ’¡ PowerBI PowerShell cmdlets are primarily for online Power BI management")
                logger.info("ðŸ’¡ For local PBIT creation, use Tabular Editor or manual methods")
                
                return False
            else:
                logger.warning("âŒ PowerShell cmdlets method only available on Windows")
                return False
                
        except Exception as e:
            logger.error(f"âŒ PowerBI cmdlets compilation error: {e}")
            return False
    
    def compile_with_python_powerbi_api(self) -> bool:
        """
        Use Python libraries to interact with Power BI REST APIs.
        Requires msal, requests, and Power BI service access.
        """
        logger.info("ðŸ”§ Attempting compilation with Python Power BI API...")
        
        try:
            # Check for required packages
            required_packages = ['msal', 'requests']
            missing_packages = []
            
            for package in required_packages:
                try:
                    __import__(package)
                except ImportError:
                    missing_packages.append(package)
            
            if missing_packages:
                logger.warning(f"âŒ Missing required packages: {', '.join(missing_packages)}")
                logger.info(f"ðŸ’¡ Install with: pip install {' '.join(missing_packages)}")
                return False
            
            # Python Power BI API method
            logger.info("ðŸ’¡ Python Power BI API method requires:")
            logger.info("   1. Azure AD app registration")
            logger.info("   2. Power BI service authentication")
            logger.info("   3. Online workspace for processing")
            logger.info("ðŸ’¡ This is a cloud-based method - not suitable for local PBIT creation")
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ Python Power BI API compilation error: {e}")
            return False
    
    def compile_with_xmla_endpoint(self) -> bool:
        """
        Use XMLA endpoint to process the model.
        This can work with local Analysis Services or Power BI Premium.
        """
        logger.info("ðŸ”§ Attempting compilation with XMLA endpoint...")
        
        try:
            # Check for required packages for XMLA
            required_packages = ['adodbapi', 'pythonnet']
            available_packages = []
            
            for package in required_packages:
                try:
                    __import__(package)
                    available_packages.append(package)
                except ImportError:
                    pass
            
            if not available_packages:
                logger.warning("âŒ XMLA packages not available")
                logger.info("ðŸ’¡ XMLA method requires:")
                logger.info("   1. pythonnet: pip install pythonnet")
                logger.info("   2. adodbapi: pip install adodbapi")
                logger.info("   3. Local Analysis Services instance")
                return False
            
            # XMLA method information
            logger.info("ðŸ’¡ XMLA endpoint method requires:")
            logger.info("   1. Local Analysis Services instance running")
            logger.info("   2. XMLA connection string")
            logger.info("   3. Model deployment to AS")
            logger.info("   4. PBIT export from connected Power BI Desktop")
            logger.info("ðŸ’¡ This is an advanced enterprise method")
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ XMLA endpoint compilation error: {e}")
            return False
    
    def compile_with_custom_zip_method(self) -> bool:
        """
        Alternative ZIP-based PBIT creation method with enhanced validation.
        This method focuses on creating the most compatible PBIT structure.
        """
        logger.info("ðŸ”§ Attempting custom ZIP-based PBIT creation...")
        
        try:
            bim_file = self.project_dir / "DataModelSchema" / "Model.bim"
            if not bim_file.exists():
                logger.error(f"âŒ Model.bim not found at {bim_file}")
                return False
            
            # Load and validate BIM
            with open(bim_file, 'r', encoding='utf-8') as f:
                bim_data = json.load(f)
            
            # Ensure proper BIM structure for PBIT
            if "model" in bim_data:
                model_data = bim_data["model"]
            else:
                model_data = bim_data
            
            # Create optimized PBIT
            self.output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with zipfile.ZipFile(self.output_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=9) as pbit:
                
                # DataModel - core model definition
                model_json = json.dumps(model_data, separators=(',', ':'), ensure_ascii=False)
                pbit.writestr("DataModel", model_json, compress_type=zipfile.ZIP_DEFLATED)
                
                # Version - PBIT format version
                pbit.writestr("Version", "3.0")
                
                # Metadata - file metadata
                metadata = {
                    "version": "3.0",
                    "createdFromTemplate": True,
                    "templateDisplayName": f"{self.output_path.stem}"
                }
                pbit.writestr("Metadata", json.dumps(metadata, separators=(',', ':')))
                
                # Settings - empty settings object
                pbit.writestr("Settings", "{}")
                
                # SecurityBindings - security configuration
                security = {"version": "3.0", "bindings": []}
                pbit.writestr("SecurityBindings", json.dumps(security, separators=(',', ':')))
                
                # Report structure
                report_layout = {
                    "id": 0,
                    "resourcePackages": [],
                    "config": json.dumps({
                        "version": "5.43",
                        "themeCollection": {"baseTheme": {"name": "CY24SU06"}},
                        "settings": {"useStylableVisualContainerHeader": True}
                    }),
                    "layoutOptimization": 0,
                    "sections": [
                        {
                            "id": 0,
                            "name": "Page1",
                            "displayName": "Page 1",
                            "visualContainers": [],
                            "config": json.dumps({
                                "visibility": 0,
                                "defaultLayout": {"displayOption": 1}
                            })
                        }
                    ],
                    "publicCustomVisuals": []
                }
                
                pbit.writestr("Report/Layout", json.dumps(report_layout, separators=(',', ':')))
            
            # Verify creation
            if self.output_path.exists() and self.output_path.stat().st_size > 100:
                logger.info(f"âœ… Custom ZIP PBIT creation successful: {self.output_path}")
                
                # Test the ZIP file
                try:
                    with zipfile.ZipFile(self.output_path, 'r') as test_zip:
                        files = test_zip.namelist()
                        logger.info(f"ðŸ“¦ PBIT contains: {', '.join(files)}")
                        return True
                except:
                    logger.error("âŒ Created PBIT file is corrupted")
                    return False
            else:
                logger.error("âŒ Custom ZIP PBIT creation failed")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Custom ZIP compilation error: {e}")
            return False
    
    def get_available_methods(self) -> List[str]:
        """Get list of available compilation methods on this system."""
        methods = []
        
        # Check Tabular Editor
        tabular_paths = [
            r"C:\Program Files (x86)\Tabular Editor\TabularEditor.exe",
            r"C:\Program Files\Tabular Editor\TabularEditor.exe",
            r"C:\Program Files\Tabular Editor 3\TabularEditor3.exe",
            r".\TabularEditor.exe"
        ]
        if any(Path(p).exists() for p in tabular_paths):
            methods.append("Tabular Editor")
        
        # Check Power BI Desktop
        pbi_paths = [
            r"C:\Program Files\Microsoft Power BI Desktop\bin\PBIDesktop.exe",
            r"C:\Program Files (x86)\Microsoft Power BI Desktop\bin\PBIDesktop.exe"
        ]
        if any(Path(p).exists() for p in pbi_paths):
            methods.append("Power BI Desktop")
        
        # Manual methods are always available
        methods.extend(["Manual PBIT Creation", "Custom ZIP Method"])
        
        return methods
    
    def create_pbit_manually(self) -> bool:
        """
        Create a .pbit file manually by understanding its structure.
        PBIT files are ZIP archives containing specific files.
        This is the most reliable fallback method.
        """
        logger.info("ðŸ”§ Attempting manual PBIT creation...")
        
        try:
            # Read the BIM model
            bim_file = self.project_dir / "DataModelSchema" / "Model.bim"
            if not bim_file.exists():
                logger.error(f"âŒ Model.bim not found at {bim_file}")
                return False
            
            logger.info(f"ðŸ“– Reading BIM model from {bim_file}")
            with open(bim_file, 'r', encoding='utf-8') as f:
                bim_content = json.load(f)
            
            # Validate BIM content
            if not isinstance(bim_content, dict):
                logger.error("âŒ Invalid BIM content - not a JSON object")
                return False
            
            logger.info("ðŸ“¦ Creating PBIT archive structure...")
            
            # Ensure output directory exists
            self.output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Create PBIT structure (it's a ZIP file)
            with zipfile.ZipFile(self.output_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as pbit_zip:
                
                # 1. Add DataModel (the BIM content, compacted)
                logger.info("ðŸ“ Adding DataModel...")
                datamodel_content = json.dumps(bim_content, separators=(',', ':'), ensure_ascii=False)
                pbit_zip.writestr("DataModel", datamodel_content.encode('utf-8'))
                
                # 2. Add Report Layout (if exists, otherwise create minimal)
                logger.info("ðŸ“„ Adding Report Layout...")
                report_layout_file = self.project_dir / "Report" / "Layout"
                if report_layout_file.exists():
                    with open(report_layout_file, 'r', encoding='utf-8') as f:
                        layout_content = f.read()
                    pbit_zip.writestr("Report/Layout", layout_content.encode('utf-8'))
                else:
                    # Create minimal but valid layout
                    minimal_layout = {
                        "id": 0,
                        "resourcePackages": [],
                        "config": json.dumps({
                            "version": "5.43",
                            "themeCollection": {
                                "baseTheme": {"name": "CY24SU06"}
                            }
                        }),
                        "layoutOptimization": 0,
                        "sections": [],
                        "publicCustomVisuals": []
                    }
                    pbit_zip.writestr("Report/Layout", json.dumps(minimal_layout, separators=(',', ':')).encode('utf-8'))
                
                # 3. Add StaticResources (if exists)
                static_resources_file = self.project_dir / "Report" / "StaticResources.json"
                if static_resources_file.exists():
                    logger.info("ðŸ“Š Adding StaticResources...")
                    with open(static_resources_file, 'r', encoding='utf-8') as f:
                        static_content = f.read()
                    pbit_zip.writestr("Report/StaticResources.json", static_content.encode('utf-8'))
                
                # 4. Add Metadata
                logger.info("ðŸ“‹ Adding Metadata...")
                metadata_file = self.project_dir / "Metadata"
                if metadata_file.exists():
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata_content = f.read()
                    pbit_zip.writestr("Metadata", metadata_content.encode('utf-8'))
                else:
                    metadata = {
                        "version": "3.0",
                        "createdFromTemplate": False
                    }
                    pbit_zip.writestr("Metadata", json.dumps(metadata, separators=(',', ':')).encode('utf-8'))
                
                # 5. Add Version
                logger.info("ðŸ”¢ Adding Version...")
                version_file = self.project_dir / "Version.txt"
                if version_file.exists():
                    with open(version_file, 'r', encoding='utf-8') as f:
                        version_content = f.read().strip()
                    pbit_zip.writestr("Version", version_content.encode('utf-8'))
                else:
                    pbit_zip.writestr("Version", "3.0".encode('utf-8'))
                
                # 6. Add Settings
                logger.info("âš™ï¸  Adding Settings...")
                settings_file = self.project_dir / "Settings"
                if settings_file.exists():
                    with open(settings_file, 'r', encoding='utf-8') as f:
                        settings_content = f.read()
                    pbit_zip.writestr("Settings", settings_content.encode('utf-8'))
                else:
                    pbit_zip.writestr("Settings", "{}".encode('utf-8'))
                
                # 7. Add SecurityBindings
                logger.info("ðŸ”’ Adding SecurityBindings...")
                security_file = self.project_dir / "SecurityBindings"
                if security_file.exists():
                    with open(security_file, 'r', encoding='utf-8') as f:
                        security_content = f.read()
                    pbit_zip.writestr("SecurityBindings", security_content.encode('utf-8'))
                else:
                    security_bindings = {
                        "version": "3.0", 
                        "bindings": []
                    }
                    pbit_zip.writestr("SecurityBindings", json.dumps(security_bindings, separators=(',', ':')).encode('utf-8'))
                
                # 8. Add DiagramLayout (if exists)
                diagram_file = self.project_dir / "DataModelSchema" / "DiagramLayout"
                if diagram_file.exists():
                    logger.info("ðŸ“ Adding DiagramLayout...")
                    with open(diagram_file, 'r', encoding='utf-8') as f:
                        diagram_content = f.read()
                    pbit_zip.writestr("DiagramLayout", diagram_content.encode('utf-8'))
                
                # 9. Add connections.json (if exists)
                connections_file = self.project_dir / "DataModelSchema" / "connections.json"
                if connections_file.exists():
                    logger.info("ðŸ”— Adding connections.json...")
                    with open(connections_file, 'r', encoding='utf-8') as f:
                        connections_content = f.read()
                    pbit_zip.writestr("DataModelSchema/connections.json", connections_content.encode('utf-8'))
            
            # Verify the PBIT file was created and has content
            if self.output_path.exists() and self.output_path.stat().st_size > 0:
                file_size = self.output_path.stat().st_size
                logger.info(f"âœ… Manual PBIT creation successful!")
                logger.info(f"ðŸ“ File: {self.output_path}")
                logger.info(f"ðŸ“ Size: {file_size:,} bytes")
                
                # Verify it's a valid ZIP file
                try:
                    with zipfile.ZipFile(self.output_path, 'r') as test_zip:
                        file_list = test_zip.namelist()
                        logger.info(f"ðŸ“¦ Contains {len(file_list)} files: {', '.join(file_list[:5])}{'...' if len(file_list) > 5 else ''}")
                        
                        # Check for required files
                        required_files = ["DataModel", "Metadata", "Version"]
                        missing_files = [f for f in required_files if f not in file_list]
                        if missing_files:
                            logger.warning(f"âš ï¸  Missing files: {', '.join(missing_files)}")
                        else:
                            logger.info("âœ… All required files present in PBIT")
                        
                        return True
                except zipfile.BadZipFile:
                    logger.error("âŒ Created file is not a valid ZIP archive")
                    return False
            else:
                logger.error("âŒ PBIT file was not created or is empty")
                return False
                
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Invalid JSON in BIM file: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ Manual PBIT creation failed: {e}")
            logger.error(f"Error type: {type(e).__name__}")
            return False


class EnhancedPBIToolsCompiler(PBIToolsCompiler):
    """Enhanced compiler with multiple fallback options."""
    
    def compile_to_pbit(self, project_dir: str, output_path: str, overwrite: bool = True) -> bool:
        """
        Enhanced compilation with multiple fallback methods.
        Tries methods in order of reliability and availability.
        """
        logger.info("ðŸ—ï¸  Starting enhanced compilation process...")
        
        # Initialize alternative compilers
        alt_compilers = AlternativeCompilers(project_dir, output_path)
        
        # Show available methods
        available_methods = alt_compilers.get_available_methods()
        logger.info(f"ðŸ”§ Available compilation methods: {', '.join(available_methods)}")
        
        # Method 1: Try pbi-tools first (if available and compatible)
        if self.auto_install:
            compatibility = handle_pbi_tools_compatibility()
            
            if compatibility.get("compatible", True):
                logger.info("ðŸ”§ Method 1: Trying pbi-tools...")
                if super().compile_to_pbit(project_dir, output_path, overwrite):
                    logger.info("âœ… pbi-tools compilation successful!")
                    return True
                logger.warning("âš ï¸  pbi-tools compilation failed, trying alternatives...")
            else:
                logger.warning(f"âš ï¸  pbi-tools incompatible: {compatibility.get('warning', 'Unknown issue')}")
                logger.info("â­ï¸  Skipping pbi-tools, trying alternatives...")
        
        # Method 2: Try Tabular Editor (most reliable alternative)
        logger.info("ðŸ”§ Method 2: Trying Tabular Editor...")
        if alt_compilers.compile_with_tabular_editor():
            logger.info("âœ… Tabular Editor compilation successful!")
            return True
        
        # Method 3: Try custom ZIP method (enhanced manual creation)
        logger.info("ðŸ”§ Method 3: Trying custom ZIP method...")
        if alt_compilers.compile_with_custom_zip_method():
            logger.info("âœ… Custom ZIP compilation successful!")
            return True
        
        # Method 4: Try standard manual PBIT creation
        logger.info("ðŸ”§ Method 4: Trying manual PBIT creation...")
        if alt_compilers.create_pbit_manually():
            logger.info("âœ… Manual PBIT creation successful!")
            return True
        
        # Method 5: Try Power BI Desktop (manual process)
        logger.info("ðŸ”§ Method 5: Trying Power BI Desktop automation...")
        if alt_compilers.compile_with_power_bi_desktop():
            logger.info("ðŸ’¡ Power BI Desktop opened for manual completion")
            logger.warning("âš ï¸  This method requires manual steps - see above instructions")
            return True  # User needs to complete manually
        
        # All methods failed
        logger.error("âŒ All compilation methods failed!")
        logger.info("ðŸ’¡ Troubleshooting suggestions:")
        logger.info("   1. Install Tabular Editor 2 (free): https://tabulareditor.com/")
        logger.info("   2. Install Power BI Desktop: https://powerbi.microsoft.com/desktop/")
        logger.info("   3. Check BIM file validity in project directory")
        logger.info("   4. Ensure sufficient disk space and permissions")
        
        return False
        logger.info("ðŸ”§ Method 3: Trying manual PBIT creation...")
        if alt_compilers.create_pbit_manually():
            return True
        
        # Method 4: Power BI Desktop automation (interactive)
        logger.info("ðŸ”§ Method 4: Power BI Desktop automation (requires manual steps)...")
        logger.info("ðŸ’¡ This method requires user interaction")
        
        try:
            choice = input("Would you like to try Power BI Desktop automation? (y/n): ").lower().strip()
            if choice == 'y':
                if alt_compilers.compile_with_power_bi_desktop():
                    return True
        except (EOFError, KeyboardInterrupt):
            logger.info("â­ï¸  Skipping Power BI Desktop automation")
        
        # All methods failed
        logger.error("âŒ All compilation methods failed")
        logger.error("ðŸ“‹ FINAL FALLBACK - Manual Instructions:")
        logger.error("   1. Open Power BI Desktop")
        logger.error(f"   2. File â†’ Open â†’ {project_dir}")
        logger.error("   3. File â†’ Export â†’ Power BI Template (.pbit)")
        logger.error(f"   4. Save as: {output_path}")
        
        return False
